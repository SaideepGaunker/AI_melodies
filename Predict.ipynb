{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.7' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/msys64/ucrt64/bin/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy.io.wavfile import write\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_fixed_size_mel_spectrogram(audio_path, target_shape=(256, 256)):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    # Generate the Mel spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "    # Convert to decibel scale\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    # Resize to the target shape (256x256)\n",
    "    mel_spectrogram_resized = cv2.resize(mel_spectrogram_db, target_shape)\n",
    "    return mel_spectrogram_resized, sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = r\"E:\\music\\f_g1.mp3\"\n",
    "destination_folder = r\"E:\\ideas\\output_audio\"\n",
    "def mel_spectrogram_to_audio(mel_spectrogram, sr):\n",
    "    # Resize back to (128, Time)\n",
    "    mel_spectrogram_resized = cv2.resize(mel_spectrogram, (mel_spectrogram.shape[1], 128))\n",
    "    # Convert from decibels to power\n",
    "    mel_spectrogram_power = librosa.db_to_power(mel_spectrogram_resized)\n",
    "    # Invert the Mel spectrogram to waveform\n",
    "    audio = librosa.feature.inverse.mel_to_audio(mel_spectrogram_power, sr=sr)\n",
    "    return audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_spectrogram(spectrogram, sr):\n",
    "    # If spectrogram has 3 channels (RGB), reduce it to a single channel for visualization\n",
    "    if len(spectrogram.shape) == 3 and spectrogram.shape[-1] == 3:\n",
    "        spectrogram = np.mean(spectrogram, axis=-1)  # Take the mean across channels\n",
    "    # Normalize the spectrogram to 0..1 for visualization\n",
    "    spectrogram = (spectrogram - np.min(spectrogram)) / (np.max(spectrogram) - np.min(spectrogram))\n",
    "    # Plot the spectrogram\n",
    "    if not destination_folder.endswith(os.path.sep):\n",
    "        destination_folder += os.path.sep\n",
    "    destination_path = os.path.join(destination_folder, os.path.basename(source_path))\n",
    "    os.rename(source_path, destination_path)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spectrogram, sr=sr, x_axis='time', y_axis='mel', cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained CycleGAN model\n",
    "def load_model(model_path):\n",
    "    try:\n",
    "        # Load the model\n",
    "        model = tf.keras.models.load_model(model_path, compile=False)\n",
    "        print(f\"Model loaded successfully from: {model_path}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model from {model_path}: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(audio_path, model_path, output_path):\n",
    "    # Step 1: Convert audio to fixed-size Mel spectrogram\n",
    "    mel_spectrogram, sr = audio_to_fixed_size_mel_spectrogram(audio_path)\n",
    "    print(\"Mel Spectrogram Shape:\", mel_spectrogram.shape)\n",
    "    display_spectrogram(mel_spectrogram, sr)\n",
    "    \n",
    "    # Step 2: Normalize the spectrogram for the model\n",
    "    mel_spectrogram_input = mel_spectrogram / np.max(np.abs(mel_spectrogram))  # Normalize\n",
    "    mel_spectrogram_input = np.stack([mel_spectrogram_input] * 3, axis=-1)  # Add 3 channels\n",
    "    mel_spectrogram_input = np.expand_dims(mel_spectrogram_input, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Step 3: Load the trained CycleGAN model\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model Input Shape:\", model.input_shape)\n",
    "\n",
    "    # Step 4: Generate the converted spectrogram\n",
    "    generated_spectrogram = model.predict(mel_spectrogram_input)\n",
    "    generated_spectrogram = np.squeeze(generated_spectrogram)  # Remove batch and channel dimensions\n",
    "    print(\"Generated Mel Spectrogram Shape:\", generated_spectrogram.shape)\n",
    "\n",
    "    # Step 5: Convert the generated spectrogram back to audio\n",
    "    generated_audio = mel_spectrogram_to_audio(generated_spectrogram, sr)\n",
    "\n",
    "    # Step 6: Save the generated audio\n",
    "    # write(output_path, sr, (generated_audio * 32767).astype(np.int16))  # Convert to 16-bit PCM format\n",
    "    print(f\"Generated audio saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "audio_path = r\"E:\\ideas\\music2 - Copy_org\\input_audio\\p1\"  # Path to the input audio file\n",
    "model_path = r\"E:\\ideas\\music2 - Copy_org\\models\\final_generator_guitar_to_piano.h5\"  # Path to the trained CycleGAN model\n",
    "output_path = r\"E:\\ideas\\music2 - copy_org\\output_audio\"  # Path to save the generated audio\n",
    "\n",
    "process_audio_file(audio_path, model_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
